{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with ERA5 high-resolution (~0.25deg) monthly means\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#introduction\">1. Introduction</a></li>\n",
    "<li><a href=\"#data_wrangling\">2. Data Wrangling</a></li>\n",
    "<li><a href=\"#exploratory\">3. Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusion\">4. Conclusion</a></li>\n",
    "<li><a href=\"#references\">5. References</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a id='introduction'></a>\n",
    "Cloud feedbacks are a major contributor to the spread of climate sensitivity in global climate models (GCMs) ([Zelinka et al. (2020)](https://doi-org.ezproxy.uio.no/10.1029/2019GL085782)]). Among the most poorly understood cloud feedbacks is the one associated with the cloud phase, which is expected to be modified with climate change ([Bjordal et al. (2020)](https://doi-org.ezproxy.uio.no/10.1038/s41561-020-00649-1)). Cloud phase bias, in addition, has significant implications for the simulation of radiative properties and glacier and ice sheet mass balances in climate models. \n",
    "\n",
    "In this context, this work aims to expand our knowledge on how the representation of the cloud phase affects snow formation in GCMs. Better understanding this aspect is necessary to develop climate models further and improve future climate predictions. \n",
    "\n",
    "* Load ERA5 data previously downloaded locally via [Jupyter Notebook - download ERA5](https://github.com/franzihe/download_ERA5)\n",
    "* find clouds: liquid-only, ice-only, mixed-phase\n",
    "* Regridd the ERA5 variables to the same horizontal resolution as high-resolution CMIP6 models with [`xesmf`](https://xesmf.readthedocs.io/en/latest/)\n",
    "* Calculate and plot the seasonal mean of the variable\n",
    "\n",
    "**Questions**\n",
    "* How is the cloud phase and snowfall varying between 1985 and 2014?\n",
    "\n",
    "\n",
    "> **_NOTE:_** We answer questions related to the comparison of CMIP models to ERA5 in another [Jupyter Notebook](../CMIP6_ERA5_CloudSat/plt_seasonal_mean.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Wrangling <a id='data_wrangling'></a>\n",
    "\n",
    "This study will compare surface snowfall, ice, and liquid water content from the Coupled Model Intercomparison Project Phase 6 ([CMIP6](https://esgf-node.llnl.gov/projects/cmip6/)) climate models (accessed through [Pangeo](https://pangeo.io/)) to the European Centre for Medium-Range Weather Forecast Re-Analysis 5 ([ERA5](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5)) data from **1985 to 2014**. We conduct statistical analysis at the annual and seasonal timescales to determine the biases in cloud phase and precipitation (liquid and solid) in the CMIP6 models and their potential connection between them. The CMIP6 data analysis can be found in the [Jupyter Notebook for CMIP6](../cmip/CMIP6_hr_1985-2014.ipynb).\n",
    "\n",
    "- Time period: 1985 to 2014\n",
    "- horizonal resolution: ~0.25deg\n",
    "- time resolution: monthly atmospheric data \n",
    "- Variables:\n",
    "  \n",
    "| shortname     |             Long name                   |      Units    |  levels |\n",
    "| ------------- |:---------------------------------------:| -------------:|--------:|\n",
    "| sf            |    snowfall                             |[m of water eq]| surface |\n",
    "| msr           |    mean_snowfall_rate                   |[kg m-2 s-1]   | surface |\n",
    "| cswc          |    specific_snow_water_content          | [kg kg-1]     |    pl   |\n",
    "| clwc          |    specific_cloud_liquid_water_content  |   [kg kg-1]   |    pl   |\n",
    "| clic          |    specific_cloud_ice_water_content     | [kg kg-1]     |    pl   |\n",
    "| t             |    temperature                          |  [K]          |    pl   |\n",
    "| 2t            |    2 metre temperature                  |  [K]          | surface |\n",
    "| tclw          |   Total column cloud liquid water       |  [kg m-2]     | single  |\n",
    "| tciw          |   Total column cloud ice water          |  [kg m-2]     | single  |\n",
    "| tp            |   Total precipitation                   |  [m]          | surface |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python packages\n",
    "- `Python` environment requirements: file [globalsnow.yml](../globalsnow.yml) \n",
    "- load `python` packages from [imports.py](../utils/imports.py)\n",
    "- load `functions` from [functions.py](../utils/functions.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7fd804458ac0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # don't output warnings\n",
    "\n",
    "# import packages\n",
    "import sys\n",
    "import os\n",
    "if os.path.isfile('/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/utils/imports.py') == True:\n",
    "    sys.path.append('/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/utils')\n",
    "    \n",
    "elif os.path.isfile('/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/utils/imports.py') == False:\n",
    "    sys.path.append('/home/franzihe/Documents/Python/eosc-nordic-climate-demonstrator/work/utils/')\n",
    "\n",
    "from imports import(xr, intake, ccrs, cy, plt, glob, cm, fct, np, da)\n",
    "xr.set_options(display_style='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open ERA5 variables\n",
    "Get the data requried for the analysis. Beforehand we downloaded the monthly averaged data on single levels and pressure levels via the Climate Data Store (CDS) infrastructure. The github repository [Download ERA5](https://github.com/franzihe/download_ERA5) gives examples on how to download the data from the CDS. We use the Jupyter Notebooks [download_Amon_single_level](https://github.com/franzihe/download_ERA5/blob/main/download_Amon_single_level.ipynb) and [download_Amon_pressure_level](https://github.com/franzihe/download_ERA5/blob/main/download_Amon_pressure_level.ipynb). Both, download the monthly means for the variables mentioned above between 1985 and 2014.\n",
    "\n",
    "> **_NOTE:_** To download from CDS a user has to have a CDS user account, please create the account [here](https://cds.climate.copernicus.eu/user/register).\n",
    "\n",
    "\n",
    "The ERA5 0.25deg data is located in the folder `/input/ERA5/monthly_means/0.25deg`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(glob('/scratch/franzihe/input/ERA5/monthly_means/0.25deg/*_Amon_ERA5_*12.nc')) > 0) == True:\n",
    "    input_data = '/scratch/franzihe/input'\n",
    "    output_data = '/scratch/franzihe/output'\n",
    "\n",
    "if (len(glob('/home/franzihe/Data/input/ERA5/monthly_means/0.25deg/*_Amon_ERA5_*12.nc')) > 0) == True:\n",
    "    input_data = '/home/franzihe/Data/input/'\n",
    "    output_data = '/home/franzihe/Data/output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_in = '{}/ERA5/monthly_means/0.25deg'.format(input_data)\n",
    "era_out = '{}/ERA5/monthly_means/1deg'.format(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_id=[\n",
    "            '2t',\n",
    "            'clic',\n",
    "            'clwc',\n",
    "            'cswc',\n",
    "            'msr',\n",
    "            'sf',\n",
    "            't', \n",
    "            'tciw',\n",
    "            'tclw',\n",
    "            'tp'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment we have downloaded 30 years (1985-2014) for ERA5. We define start and end year to ensure to only extract the 30-year period between 1985 and 2014.\n",
    "\n",
    "$\\rightarrow$ Define a start and end year\n",
    "\n",
    "We will load all available variables into one xarray dataset with `xarray.open_mfdataset(file)` and select the time range [by name](https://xarray.pydata.org/en/stable/user-guide/indexing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "starty = 1985; endy = 2014\n",
    "year_range = range(starty, endy+1)\n",
    "# Input data from ERA5 with a resolution of 0.25x0.25deg to be regridded\n",
    "era_file_in = glob('{}/*_Amon_ERA5_*12.nc'.format(era_in, ))       # search for data in the local directory \n",
    "ds_era = xr.open_mfdataset(era_file_in)\n",
    "ds_era = ds_era.sel(time = ds_era.time.dt.year.isin(year_range)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pressure array \n",
    "ds_era['pressure'] = xr.DataArray(data=da.ones(shape = ds_era['clwc'].shape, chunks=(120, 37, 721, 1440/2)), \n",
    "                                                               dims=list(ds_era['clwc'].dims), \n",
    "                                                               coords=[ds_era.time.values, ds_era.level.values, ds_era.latitude.values, ds_era.longitude.values])\n",
    "\n",
    "ds_era['pressure'] = ds_era['pressure']*ds_era['level'][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change attributes matching CMIP6 data\n",
    "\n",
    "We will assign the attributes to the variables to make CMIP6 and ERA5 variables comperable.\n",
    "\n",
    "The data [documentation of monthly means](https://confluence.ecmwf.int/pages/viewpage.action?pageId=82870405#ERA5:datadocumentation-Monthlymeans) gives information about the accumulations in monthly means (of daily means, stream=moda/edmo). Hence, the precipitation variables have been scaled to have an \"effective\" processing period of one day, so for accumulations in these streams\n",
    "* [`sf`](https://apps.ecmwf.int/codes/grib/param-db?id=144) is in **m of water per day** $\\rightarrow$  multiply by **1000** to get **kg m-2 day-1** or **mmday-1**.\n",
    "\n",
    "\n",
    "* [`tp`](https://apps.ecmwf.int/codes/grib/param-db?id=228) is in **m** $\\rightarrow$ Multiply by **1000** to get **mm**\n",
    "* [`ciwc`](https://apps.ecmwf.int/codes/grib/param-db?id=247), [`clwc`](https://apps.ecmwf.int/codes/grib/param-db?id=246), and [`cswc`](https://apps.ecmwf.int/codes/grib/param-db?id=76) is in **kg kg-1**    $\\rightarrow$ Multiply by **1000** to get **g kg-1**\n",
    "* [`msr`](https://apps.ecmwf.int/codes/grib/param-db?id=235031) is in **kg m-2 s-1** $\\rightarrow$ Multiply by **86400** to get **mm day-1**\n",
    "* [`tciw`](https://apps.ecmwf.int/codes/grib/param-db?id=79) and [`tclw`](https://apps.ecmwf.int/codes/grib/param-db?id=78) is in **kg m-2** $\\rightarrow$ Multiply by **1000** to get **g m-2**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variable name to variable id\n",
    "variable_id[variable_id.index('2t')] = 't2m'\n",
    "variable_id[variable_id.index('clic')] = 'ciwc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_id in variable_id:\n",
    "    \n",
    "    if var_id == 'ciwc' or var_id == 'clwc' or var_id == 'cswc' or var_id == 'sf' or var_id == 'tciw' or var_id == 'tclw' or var_id == 'tp':\n",
    "        ds_era[var_id] = ds_era[var_id]*1000\n",
    "        \n",
    "        if var_id == 'ciwc':\n",
    "            ds_era[var_id].attrs = {'units': 'g kg-1', 'long_name':'Specific cloud ice water content'}\n",
    "        if var_id == 'clwc':\n",
    "            ds_era[var_id].attrs = {'units': 'g kg-1', 'long_name':'Specific cloud liquid water content'}\n",
    "        if var_id == 'cswc':\n",
    "            ds_era[var_id].attrs = {'units': 'g kg-1', 'long_name':'Specific snow water content'}\n",
    "        if var_id == 'sf':\n",
    "            ds_era[var_id].attrs = {'units': 'mm day-1', 'long_name': 'Snowfall',}\n",
    "        if var_id == 'tciw':\n",
    "            ds_era[var_id].attrs = {'units': 'g m-2', 'long_name': 'Total column cloud ice water'}\n",
    "        if var_id == 'tclw':\n",
    "            ds_era[var_id].attrs = {'units': 'g m-2', 'long_name': 'Total column cloud liquid water'}\n",
    "        if var_id == 'tp':\n",
    "            ds_era[var_id].attrs = {'units': 'mm', 'long_name': 'Total precipitation'}\n",
    "        \n",
    "    if var_id == 'msr':\n",
    "        ds_era[var_id] = ds_era[var_id]*86400\n",
    "        ds_era[var_id].attrs = {'units': 'mm day-1', 'long_name': 'Mean snowfall rate'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find mixed-phase clouds\n",
    "\n",
    "To get a relationship between cloud phase and snowfall amount we find mixed-phase clouds and associated precipitation in each grid cell. $\\rightarrow$ \n",
    "\n",
    "\n",
    "1. calculate percentages in each level\n",
    "   1. IWC + LWC = 100%\n",
    "   2. IWC/(IWC + LWC) * 100 = percent_iwc %\n",
    "   3. LWC/(IWC + LWC) * 100 = percent_lwc %\n",
    "2. find level where percent_iwc == 50% and percent_lwc == 50%\n",
    "3. get values where level 50/50\n",
    "   1. P(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   2. T(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   3. IWC(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   4. LWC(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   5. SWC(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   6. sf(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   7. tp(percent_iwc == 50% and percent_lwc == 50%)\n",
    "\n",
    "3. find, where precipitation is >= 0.25 mm day-1 and IWC+LWC >= 0.01 g kg-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create occcurence array \n",
    "for var_id in list(ds_era.keys()):\n",
    "    ds_era[var_id + '_occurence'] = xr.DataArray(data=da.ones(shape = (ds_era['time'].shape[0],ds_era['latitude'].shape[0], ds_era['longitude'].shape[0]), chunks=(120, 721, 1440/2)), \n",
    "                                                                dims=[ds_era['time'].dims[0],ds_era['latitude'].dims[0], ds_era['longitude'].dims[0]] , \n",
    "                                                                coords=[ds_era['time'].values,ds_era['latitude'].values, ds_era['longitude'].values] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary from the list of datasets we want to use for the IWC/LWC statistics\n",
    "Calculate the IWC/LWC statistics given by the values. Setting the value to 0.5 will find the level in the atmosphere where IWC and LWC are 50/50. Setting it to a value of 0.7 will find the level where IWC is 70% while LWC is 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_dict = dict()\n",
    "dset_dict['era'] = ds_era\n",
    "iwc_stat = {'50':0.5, '70':0.7, '30':0.5}\n",
    "for i in iwc_stat.items():\n",
    "    dset_dict['era_{}'.format(i[0])] = xr.Dataset()\n",
    "    dset_dict['era_{}'.format(i[0])] = fct.find_IWC_LWC_level(ds_era, var1 ='ciwc', var2='clwc', value=i[1], ds_out=dset_dict['era_{}'.format(i[0])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regrid ERA5 data to common NorESM2-MM grid <a id='regrid_hz'></a>\n",
    "\n",
    "We want to conduct statistical analysis at the annual and seasonal timescales to determine the biases in cloud phase and precipitation (liquid and solid) for the CMIP6 models in comparison to ERA5. \n",
    "\n",
    "The ERA5 data has a nominal resolution of 0.25 deg and has to be regridded to the same horizontal resolution as the NorESM2-MM. Hence we will make use of the python package `xesmf` and [decreasing resolution](https://xesmf.readthedocs.io/en/latest/notebooks/Compare_algorithms.html#Decreasing-resolution), [Limitations and warnings](https://xesmf.readthedocs.io/en/latest/notebooks/Masking.html?highlight=conservative#Limitations-and-warnings).  \n",
    "\n",
    "$\\rightarrow$ Define NorESM2-MM as the reference grid `ds_out`.\n",
    "\n",
    "Save all variables in one file and each variable to a `netcdf` datasets between 1985 an 2014, locally.\n",
    "\n",
    "> **_NOTE:_** This can take a while, so be patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the output grid from NorESM\n",
    "cmip_file = '/scratch/franzihe/input/cmip6_hist/1deg/grid_NorESM2-MM.nc'\n",
    "ds_out = xr.open_dataset(cmip_file)\n",
    "\n",
    "\n",
    "# create dictionary for reggridded data\n",
    "ds_gridded_dict = dict()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for keys in dset_dict.keys():\n",
    "\n",
    "    # select where data should be saved\n",
    "    filename = '{}_Amon_1deg_{}01_{}12.nc'.format(keys,starty, endy)\n",
    "    era_file_out = era_out + '/Amon/' + filename\n",
    "    files = glob(era_file_out)\n",
    "\n",
    "\n",
    "\n",
    "    # Regrid data\n",
    "    ds_in_regrid = fct.regrid_data(dset_dict[keys], ds_out)\n",
    "\n",
    "    # Shift the longitude from 0-->360 to -180-->180 and sort by longitude and time\n",
    "    ds_in_regrid = ds_in_regrid.assign_coords(lon=(((ds_in_regrid.lon + 180) % 360) - 180)).sortby('lon').sortby('time')\n",
    "\n",
    "    # create dataset with all statistics\n",
    "    ds_gridded_dict[keys] = ds_in_regrid\n",
    "\n",
    "    # if era_file_out in files:\n",
    "    #     print('{} is downloaded'.format(era_file_out))\n",
    "    #     counter += 1\n",
    "    #     print('Have regridded in total: {:} files'.format(str(counter))) \n",
    "    # else: # Save to netcdf file\n",
    "    ds_in_regrid.to_netcdf(era_file_out)\n",
    "    print('file written: {}'.format(era_file_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save each individual variable to a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this really necessary?\n",
    "# counter = 0\n",
    "\n",
    "# for keys in dset_dict.keys():\n",
    "#     for var_id in dset_dict[keys].data_vars:\n",
    "#         # select where data should be saved\n",
    "#         filename = '{}_Amon_1deg_{}01_{}12.nc'.format(var_id, starty, endy)\n",
    "#         era_file_out = era_out + '/Amon/' + filename\n",
    "#         files = glob(era_file_out)\n",
    "        \n",
    "#         if era_file_out in files:\n",
    "#             print('{} is downloaded'.format(era_file_out))\n",
    "#             counter += 1\n",
    "#             print('Have regridded in total: {:} files'.format(str(counter))) \n",
    "#         else: # Save to netcdf file\n",
    "#             ds_gridded_dict[keys][var_id].to_netcdf(era_file_out)\n",
    "#             print('file written: {}'.format(era_file_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect all models into one Dataset with new coordinate 'model'\n",
    "\n",
    "We will create a `xarray.Dataset` with all ERA5 data, after the interpolation to the same horizonal (and vertical) resolution. This step will make the next steps easier, as we will not need the the full dictonary key and can just use the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds = list(dset_dict.values())\n",
    "_coord = list(dset_dict.keys())\n",
    "ds_era_025deg = xr.concat(objs=_ds, dim=_coord, coords=\"all\").rename({'concat_dim':'model'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds = list(ds_gridded_dict.values())\n",
    "_coord = list(ds_gridded_dict.keys())\n",
    "ds_era_1deg = xr.concat(objs=_ds, dim=_coord, coords=\"all\").rename({'concat_dim':'model'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_SH = (-90, -30); lat_NH = (30,90); step = 15\n",
    "iteration_SH = range(lat_SH[1], lat_NH[0], -step)\n",
    "iteration_NH = range(lat_NH[0], lat_NH[1], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_era_025deg = fct.rename_coords_lon_lat(ds_era_025deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_pres = ds_era_025deg['pressure'] == ds_era_025deg['pressure'].max('level')\n",
    "\n",
    "ds_era_025deg['t_plev'] = (ds_era_025deg['t'].where(filter_pres)).idxmax(dim='level')\n",
    "for _lat in iteration_SH:\n",
    "    ds_era_025deg['t_plev_season_{}_{}'.format(_lat, _lat-step)] = ds_era_025deg['t_plev'].sel(lat = slice(_lat-step, _lat)).groupby('time.season').mean(('time', 'lat', 'lon'), keep_attrs=True, skipna=True)\n",
    "    ds_era_025deg['sf_plev_season_{}_{}'.format(_lat, _lat-step)] = ds_era_025deg['sf'].sel(lat = slice(_lat-step, _lat)).groupby('time.season').mean(('time', 'lat', 'lon'), keep_attrs=True, skipna=True)\n",
    "\n",
    "\n",
    "for _lat in iteration_NH:\n",
    "    ds_era_025deg['t_plev_season_{}_{}'.format(_lat, _lat+step)] = ds_era_025deg['t_plev'].sel(lat = slice(_lat+step, _lat)).groupby('time.season').mean(('time', 'lat', 'lon'), keep_attrs=True, skipna=True)\n",
    "    ds_era_025deg['sf_plev_season_{}_{}'.format(_lat, _lat+step)] = ds_era_025deg['sf'].sel(lat = slice(_lat+step, _lat)).groupby('time.season').mean(('time', 'lat', 'lon'), keep_attrs=True, skipna=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.plot.scatter(ds_era_025deg, x='t_plev_season_{}_{}'.format(_lat, _lat+step), y='sf_plev_season_{}_{}'.format(_lat, _lat+step), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m ds_era_025deg[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues:\n\u001b[0;32m----> 2\u001b[0m     plt\u001b[39m.\u001b[39;49mplot(ds_era_025deg[\u001b[39m'\u001b[39;49m\u001b[39mt_plev_season_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(_lat, _lat\u001b[39m+\u001b[39;49mstep)]\u001b[39m.\u001b[39;49msel(model\u001b[39m=\u001b[39;49mmodel, season\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mDJF\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      3\u001b[0m              ds_era_025deg[\u001b[39m'\u001b[39;49m\u001b[39msf_plev_season_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(_lat, _lat\u001b[39m+\u001b[39;49mstep)]\u001b[39m.\u001b[39;49msel(model\u001b[39m=\u001b[39;49mmodel,season\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mDJF\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/pyplot.py?line=2754'>2755</a>\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/pyplot.py?line=2755'>2756</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/pyplot.py?line=2756'>2757</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/pyplot.py?line=2757'>2758</a>\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/pyplot.py?line=2758'>2759</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_axes.py?line=1389'>1390</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_axes.py?line=1390'>1391</a>\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_axes.py?line=1391'>1392</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_axes.py?line=1628'>1629</a>\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_axes.py?line=1629'>1630</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_axes.py?line=1630'>1631</a>\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[0;32m-> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_axes.py?line=1631'>1632</a>\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_axes.py?line=1632'>1633</a>\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_axes.py?line=1633'>1634</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_base.py?line=309'>310</a>\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_base.py?line=310'>311</a>\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_base.py?line=311'>312</a>\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(this, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_base.py:487\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_base.py?line=483'>484</a>\u001b[0m         kw[prop_name] \u001b[39m=\u001b[39m val\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_base.py?line=485'>486</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(xy) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_base.py?line=486'>487</a>\u001b[0m     x \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_base.py?line=487'>488</a>\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/axes/_base.py?line=488'>489</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/cbook/__init__.py:1304\u001b[0m, in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/cbook/__init__.py?line=1301'>1302</a>\u001b[0m \u001b[39m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/cbook/__init__.py?line=1302'>1303</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/cbook/__init__.py?line=1303'>1304</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49matleast_1d(x)\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/cbook/__init__.py?line=1304'>1305</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/cbook/__init__.py?line=1305'>1306</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/cbook/__init__.py?line=1306'>1307</a>\u001b[0m         \u001b[39m# work around\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/cbook/__init__.py?line=1307'>1308</a>\u001b[0m         \u001b[39m# https://github.com/pandas-dev/pandas/issues/27775 which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/cbook/__init__.py?line=1318'>1319</a>\u001b[0m         \u001b[39m# This code should correctly identify and coerce to a\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/matplotlib/cbook/__init__.py?line=1319'>1320</a>\u001b[0m         \u001b[39m# numpy array all pandas versions.\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/numpy/core/shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/numpy/core/shape_base.py?line=62'>63</a>\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/numpy/core/shape_base.py?line=63'>64</a>\u001b[0m \u001b[39mfor\u001b[39;00m ary \u001b[39min\u001b[39;00m arys:\n\u001b[0;32m---> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/numpy/core/shape_base.py?line=64'>65</a>\u001b[0m     ary \u001b[39m=\u001b[39m asanyarray(ary)\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/numpy/core/shape_base.py?line=65'>66</a>\u001b[0m     \u001b[39mif\u001b[39;00m ary\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/numpy/core/shape_base.py?line=66'>67</a>\u001b[0m         result \u001b[39m=\u001b[39m ary\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/common.py:143\u001b[0m, in \u001b[0;36mAbstractArray.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/common.py?line=141'>142</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m: Any, dtype: DTypeLike \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/common.py?line=142'>143</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py:641\u001b[0m, in \u001b[0;36mDataArray.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=631'>632</a>\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=632'>633</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalues\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=633'>634</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=634'>635</a>\u001b[0m \u001b[39m    The array's data as a numpy.ndarray.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=635'>636</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=638'>639</a>\u001b[0m \u001b[39m    type does not support coercion like this (e.g. cupy).\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=639'>640</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=640'>641</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariable\u001b[39m.\u001b[39;49mvalues\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py:510\u001b[0m, in \u001b[0;36mVariable.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=506'>507</a>\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=507'>508</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalues\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=508'>509</a>\u001b[0m     \u001b[39m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=509'>510</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _as_array_or_item(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py:250\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=235'>236</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_as_array_or_item\u001b[39m(data):\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=236'>237</a>\u001b[0m     \u001b[39m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=237'>238</a>\u001b[0m \u001b[39m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=238'>239</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=247'>248</a>\u001b[0m \u001b[39m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=248'>249</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=249'>250</a>\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(data)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=250'>251</a>\u001b[0m     \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/variable.py?line=251'>252</a>\u001b[0m         \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mM\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/array/core.py:1581\u001b[0m, in \u001b[0;36mArray.__array__\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/array/core.py?line=1579'>1580</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/array/core.py?line=1580'>1581</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute()\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/array/core.py?line=1581'>1582</a>\u001b[0m     \u001b[39mif\u001b[39;00m dtype \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m dtype:\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/array/core.py?line=1582'>1583</a>\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mastype(dtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py:288\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=263'>264</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=264'>265</a>\u001b[0m     \u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=265'>266</a>\u001b[0m \n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=266'>267</a>\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=285'>286</a>\u001b[0m \u001b[39m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=286'>287</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=287'>288</a>\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39;49m, traverse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=288'>289</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py:571\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=567'>568</a>\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=568'>569</a>\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=570'>571</a>\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=571'>572</a>\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py:79\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=75'>76</a>\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=76'>77</a>\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=78'>79</a>\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=79'>80</a>\u001b[0m     pool\u001b[39m.\u001b[39;49msubmit,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=80'>81</a>\u001b[0m     pool\u001b[39m.\u001b[39;49m_max_workers,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=81'>82</a>\u001b[0m     dsk,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=82'>83</a>\u001b[0m     result,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=83'>84</a>\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=84'>85</a>\u001b[0m     get_id\u001b[39m=\u001b[39;49m_thread_get_id,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=85'>86</a>\u001b[0m     pack_exception\u001b[39m=\u001b[39;49mpack_exception,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=86'>87</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=87'>88</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=89'>90</a>\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=90'>91</a>\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py:496\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=493'>494</a>\u001b[0m \u001b[39mwhile\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mwaiting\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mready\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mrunning\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=494'>495</a>\u001b[0m     fire_tasks(chunksize)\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=495'>496</a>\u001b[0m     \u001b[39mfor\u001b[39;00m key, res_info, failed \u001b[39min\u001b[39;00m queue_get(queue)\u001b[39m.\u001b[39mresult():\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=496'>497</a>\u001b[0m         \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=497'>498</a>\u001b[0m             exc, tb \u001b[39m=\u001b[39m loads(res_info)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py:134\u001b[0m, in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=132'>133</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mqueue_get\u001b[39m(q):\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=133'>134</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m q\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/queue.py?line=168'>169</a>\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/queue.py?line=169'>170</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/queue.py?line=170'>171</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/queue.py?line=171'>172</a>\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/queue.py?line=172'>173</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/threading.py?line=309'>310</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/threading.py?line=310'>311</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/threading.py?line=311'>312</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/threading.py?line=312'>313</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/threading.py?line=313'>314</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in ds_era_025deg['model'].values:\n",
    "    plt.plot(ds_era_025deg['t_plev_season_{}_{}'.format(_lat, _lat+step)].sel(model=model, season='DJF'),\n",
    "             ds_era_025deg['sf_plev_season_{}_{}'.format(_lat, _lat+step)].sel(model=model,season='DJF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create seasonal mean/spread of all ERA5 data\n",
    "\n",
    "...and plot seasonal mean of each individual, like ERA5-0.25deg resolution, ERA5-1deg resolution, and the IWC/LWC statistics for 50%, 70%, 30% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_mean_std(ds, var,):\n",
    "    ds[var+'_season_mean'] = ds[var].groupby('time.season').mean('time', keep_attrs = True)\n",
    "    ds[var+'_season_std']  = ds[var].groupby('time.season').std('time', keep_attrs = True)\n",
    "\n",
    "    return(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seasonal mean of variables\n",
    "for var_id in list(ds_era.keys()):\n",
    "    ds_era = seasonal_mean_std(ds_era, var_id)\n",
    "\n",
    "for var_id in list(ds_era_30.keys()):\n",
    "    ds_era_30 = seasonal_mean_std(ds_era_30, var_id)\n",
    "for var_id in list(ds_era_50.keys()):\n",
    "    ds_era_50 = seasonal_mean_std(ds_era_50, var_id)\n",
    "for var_id in list(ds_era_70.keys()):\n",
    "    ds_era_70 = seasonal_mean_std(ds_era_70, var_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_id in list(ds_era.keys()):\n",
    "\n",
    "\n",
    "    # Plot seasonal mean\n",
    "    fig, axs, im = fct.plt_spatial_seasonal_mean(ds_era[var_id+'_season_mean'], var_id, title='ERA5 MEAN ({} - {})'.format(starty, endy))\n",
    "\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([1, 0.15, 0.025, 0.7])\n",
    "    cb = fig.colorbar(im, cax=cbar_ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "    cb.set_label(label='MEAN - {}'.format(fct.plt_dict[var][fct.plt_dict['header'].index('label')], weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save figure to png\n",
    "    figdir = '/uio/kant/geo-metos-u1/franzihe/Documents/Figures/ERA5/'\n",
    "    figname = '{}_season_1deg_{}_{}.png'.format(var_id, starty, endy)\n",
    "    plt.savefig(figdir + figname, format = 'png', bbox_inches = 'tight', transparent = False)\n",
    "\n",
    "    # Plot seasonal mean and std\n",
    "    fig, axs, im = fct.plt_spatial_seasonal_mean(ds_era[var_id+'_season_mean'], var_id, title='ERA5 MEAN ({} - {})'.format(starty, endy))\n",
    "\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([1, 0.15, 0.025, 0.7])\n",
    "    cb = fig.colorbar(im, cax=cbar_ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "    cb.set_label(label='MEAN - {}'.format(fct.plt_dict[var][fct.plt_dict['header'].index('label')], weight='bold')\n",
    "\n",
    "    for ax, i in zip(axs, ds_era[var_id+'_season_std'].season):\n",
    "        sm = ds_era[var_id+'_season_std'].sel(season=i).plot.contour(ax=ax, transform=ccrs.PlateCarree(), \n",
    "                                                                        robust=True,\n",
    "                                                                        vmin = vmin_std, vmax = vmax_std,\n",
    "                                                                        levels = 6,\n",
    "                                                                        cmap=cm.lajolla,\n",
    "                                                                        add_colorbar=False)\n",
    "        \n",
    "    cbar_ax = fig.add_axes([1.10, 0.15, 0.025, 0.7])\n",
    "    sb = fig.colorbar(sm, cax=cbar_ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "    sb.set_label(label='STD - {}'.format(label), weight='bold')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find liquid, ice only, mixed phase cloud. Plot histogram of observed snowfall amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FH  11:04 AM\n",
    "Ok. There is something I don't understand.\n",
    "You have this in line 165: P_idx=sum(P>100,1)>0;%find hours where seeder feeder might be happening What is the P>100? Pressure level?\n",
    "RD  11:38 AM\n",
    "hmmm i dont remember. Ill have a look in a bit\n",
    "FH  11:39 AM\n",
    "sure :smile:\n",
    "RD  1:34 PM\n",
    "okay so i just checked\n",
    "1:34\n",
    "that tells me if there is a true difference between cloud layers\n",
    "1:35\n",
    "so basically the T change will go from 0 (where there is no ice cloud) to the T of the cloud\n",
    "FH  1:36 PM\n",
    "true difference between the temperatures in the cloud layers?!\n",
    "RD  1:36 PM\n",
    "so it makes sure that the code is not tricked by local minimums in T but that there is truly an IWC free layer\n",
    "1:37\n",
    "ya so its to avoid situations where you have\n",
    "250|\n",
    "245\n",
    "248\n",
    "1:37\n",
    "showing up as a local minimum and therefore it thinks that is a cloud free layer\n",
    "1:39\n",
    "it was a way to retain the cloud temperatures and find the cloud free situations\n",
    "1:40\n",
    "maybe not the best way but it was an easy way i think\n",
    "FH  1:44 PM\n",
    "Ok. I have to think a little about it. So you find the local minimum of the temperature and check at the same time if there is ice?\n",
    "What I also don't understand is what you do in the next line. P_idx=sum(P>100,1)>0;%find hours where seeder feeder might be happening\n",
    "RD  1:46 PM\n",
    "ya so that just finds the profiles where there is seeder feeder based on the gaps in the iwc\n",
    "1:47\n",
    "so if the T multiplied by whether there is iwc or not (1 or 0)\n",
    "1:47\n",
    "so if the T of this multiplication has points where the change is greater than 100, it identifies it as a profile with seeder feeder\n",
    "1:49\n",
    "because in each .nc file there tons of 3 hourly profiles\n",
    "1:49\n",
    "so this is a quick way to filter out the ones with seeder-feeder and without\n",
    "FH  1:49 PM\n",
    "Got it, I think. I started doing it just with my data. But if everything goes well we can just use the function for the seeder-feeder paper\n",
    "New\n",
    "RD  1:50 PM\n",
    "you cant just use whether there is ice or not (1 or 0) because the diff will mess things up\n",
    "1:50\n",
    "you will go from 0 to 1 when the cloud starts and then back to 0 then back 1 at cloud top\n",
    "1:50\n",
    "so this was a way to work around that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f24944080b15318569c1ef785be98f8dd5a0531d3a23558ab9e7edab213d92e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('globalsnow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
