{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CloudSat R05 data and create the monthly mean of \n",
    "# information of variables: http://www.cloudsat.cira.colostate.edu/data-products/level-2c/2c-snow-profile?term=90\n",
    "# Documentation: http://www.cloudsat.cira.colostate.edu/sites/default/files/products/files/2C-SNOW-PROFILE_PDICD.P1_R05.rev0_.pdf\n",
    "\n",
    "\n",
    "# 1D variables\n",
    "# 'snowfall_rate_sfc'\n",
    "\n",
    "# 2D variables\n",
    "# 'Height'\n",
    "# 'snowfall_rate'\n",
    "# 'snow_water_content'\n",
    "\n",
    "\n",
    "# necessary variables\n",
    "        # 'Latitude'\n",
    "        # 'Longitude'\n",
    "        # 'Vertical_binsize'\n",
    "        # profile times as YYYYMMDD-HH-MM-SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # don't output warnings\n",
    "\n",
    "# import packages\n",
    "from imports import(glob, pySD, pyHDF, read_var_eos, xr, np, datetime, timedelta, fct)\n",
    "\n",
    "# reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2008\n",
    "\n",
    "\n",
    "one_D = False\n",
    "two_D = True\n",
    "\n",
    "\n",
    "\n",
    "available_month = {\n",
    "                   '1':'01',\n",
    "                   '2':'02',\n",
    "                   '3':'03',\n",
    "                   '4':'04', \n",
    "                   '5':'05', \n",
    "                   '6':'06', \n",
    "                   '7':'07',\n",
    "                   '8':'08', \n",
    "                   '9':'09', \n",
    "                   '10':'10', \n",
    "                   '11':'11', \n",
    "                   '12':'12'\n",
    "                  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = '/tos-project2/NS9600K/data'\n",
    "path = '/scratch/franzihe'\n",
    "datapath = '{:}/input/cloudsat/2C-SNOW-PROFILE.P1_R05'.format(path)\n",
    "ff_cs = sorted(glob('{}/{}/*/*.hdf'.format(datapath, year, )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '{:}/input/cloudsat/ECMWF-AUX.P_R05'.format(path)\n",
    "ff_ec = sorted(glob('{}/{}/*/*.hdf'.format(filepath, year, )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if one_D == True:\n",
    "    # 1D variables\n",
    "    variables = {\n",
    "                # 'DEM_elevation'               : 'm',        #Elevation in meters above Mean Sea Level. A value of -9999 indicates ocean. A value of 9999 indicates an error in calculation of the elevation.\n",
    "                # 'Vertical_binsize'            : '',         #effective vertical height of the radar range bin.\n",
    "                'snowfall_rate_sfc'           : 'mm h-1',   #Surface snowfall rate in mm of liquid water per hour. The specified range is typical. \n",
    "                # 'snowfall_rate_sfc_uncert'    : '',         #The estimated 1-sigma uncertainty of the surface snowfall rate in mm of liquid water per hour. The specified range is typical.\n",
    "                # 'snowfall_rate_sfc_confidence': '',         #Flag indicating the relative quality of the surface snowfall rate estimate. 4: High confidence\n",
    "    }\n",
    "\n",
    "if two_D == True:\n",
    "    # 2D variables\n",
    "    variables = {\n",
    "                # 'Height'                    : '',               #Height of the radar range bins in meters above mean sea level.\n",
    "                'snowfall_rate'             : 'mm h-1',         #Profile of snowfall rates in the precipitating column in mm of liquid water per hour. The specified range is typical.\n",
    "                # 'snowfall_rate_uncert'      : '',               #The estimated 1-sigma uncertainties of the snowfall rates in the precipitating column. The specified range is typical.\n",
    "                # 'snow_water_content'        : 'g kg-1',          #Profile of snow water content in the precipitating column in grams per m^3. The specified range is typical.\n",
    "                # 'snow_water_content_uncert' : '',                #The estimated 1-sigma uncertainties of the snow water contents in the precipitating column in grams per m^3. The specified range is typical.\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_grid = np.array([24., 25., 26., 27., 28., 29., 30., 32., 33., \n",
    "                            34., 35., 37., 38., 40., 41., 43., 44., 45.,\n",
    "                            48., 50., 52., 54., 55., 58., 60., 63., 65., \n",
    "                            68., 70., 73., 75., 80., 83., 85., 90., 93., \n",
    "                            98.,100., 105., 110., 113., 115., 120., 125., 130., \n",
    "                            135., 140., 145., 155., 160., 165., 170., 180., 185., \n",
    "                            190., 200., 210., 215., 225., 230., 240., 250., 260., \n",
    "                            270., 280., 290., 300., 310., 320., 330., 345., 360., \n",
    "                            370., 380., 395., 400., 425., 440., 450., 470., 480., \n",
    "                            500., 515., 530., 550., 570., 585., 600., 625., 645., \n",
    "                            665., 685., 700., 725., 750., 770., 800., 825., 850.,\n",
    "                            870., 900., 925., 950., 988., 1000., 1010,  1015,  1020,\n",
    "                            np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,\n",
    "                            np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for month, mm in available_month.items():\n",
    "    if one_D == True:\n",
    "        ds = xr.Dataset(\n",
    "                data_vars=dict(\n",
    "                    Profile_time=(['nray'], np.empty(shape = (0,), dtype='datetime64[s]')),\n",
    "                    Latitude    =(['nray'], np.empty(shape = (0,), )),\n",
    "                    Longitude   =(['nray'], np.empty(shape = (0,), )),\n",
    "                    Data_quality=(['nray'], np.empty(shape = (0,), )),\n",
    "                                ),\n",
    "                                coords=dict(nray=([]), nbin=([])), \n",
    "                                attrs=None)\n",
    "    if two_D == True:\n",
    "        ds = xr.Dataset(\n",
    "                data_vars=dict(\n",
    "                    Profile_time=(['nray'], np.empty(shape = (0,), dtype='datetime64[s]')),\n",
    "                    Latitude    =(['nray'], np.empty(shape = (0,), )),\n",
    "                    Longitude   =(['nray'], np.empty(shape = (0,), )),\n",
    "                    Data_quality=(['nray'], np.empty(shape = (0,), )),\n",
    "                    pressure    =(['nray', 'nbin'], np.empty(shape = (0, 0), )),\n",
    "                    temperature =(['nray', 'nbin'], np.empty(shape = (0, 0), ))\n",
    "                                ),\n",
    "                                coords=dict(nray=([]), nbin=([])), \n",
    "                                attrs=None)\n",
    "    for var, unit in variables.items():\n",
    "        # create new variable \n",
    "        if one_D == True:\n",
    "            ds[var] = xr.DataArray(\n",
    "                    data = np.full(shape = (0,), fill_value=np.nan),\n",
    "                    dims = ['nray'],\n",
    "                    attrs= {'units': unit}\n",
    "                )\n",
    "        if two_D == True:\n",
    "            ds[var] = xr.DataArray(\n",
    "                    data = np.full(shape = (0, 0), fill_value=np.nan ),\n",
    "                    dims = ['nray', 'nbin'],\n",
    "                    attrs= {'units': unit}\n",
    "                )\n",
    "        filename = '{var}_{year}{month}.nc'.format(var = var, year = year, month = mm)\n",
    "        savepath = '{path}/output/cloudsat/2C-SNOW_onemonth_onevariable/{year}/'.format(path = path, year = year)\n",
    "        files = glob(savepath + filename)\n",
    "            \n",
    "        if savepath + filename in files:\n",
    "            print('{savepath}{filename} is downloaded'.format(savepath = savepath, filename = filename))\n",
    "            counter += 1\n",
    "            print('Have downloaded in total: {:} files'.format(str(counter)))\n",
    "        else:\n",
    "            for i in range(2):#len(ff_cs)):\n",
    "                # for i in range(6): # read in one file and bring 2D Variables on a common pressure grid \n",
    "                year = int(ff_cs[i].split('/')[-3])\n",
    "                doy  = int(ff_cs[i].split('/')[-2])   # day of the year\n",
    "                _t = datetime(year, 1, 1) + timedelta(doy -1)    # create date\n",
    "\n",
    "                if _t.month != int(month):\n",
    "                    continue\n",
    "                elif _t.month == int(month):\n",
    "                    \n",
    "                    # Read in CloudSat\n",
    "                    f_SD_ptr = pySD.SD(ff_cs[i], pySD.SDC.READ)\n",
    "                    f_VD_ptr = pyHDF.HDF(ff_cs[i], pyHDF.HC.READ)\n",
    "\n",
    "                    # get profile times from file\n",
    "                    Profile_time = read_var_eos.get_profile_times(f_VD_ptr)\n",
    "\n",
    "                    # get geolocation\n",
    "                    _lat = read_var_eos.get_1D_var(f_VD_ptr, 'Latitude') #Spacecraft Geodetic Latitude.\n",
    "                    _lon = read_var_eos.get_1D_var(f_VD_ptr, 'Longitude') #Spacecraft geodetic longitude\n",
    "\n",
    "                    # get data quality\n",
    "                    _Data_quality = read_var_eos.get_1D_var(f_VD_ptr, 'Data_quality') #Flags indicating data quality. If 0, then data is of good quality.\n",
    "\n",
    "                    # get variable\n",
    "                    if one_D == True:\n",
    "                        _var = read_var_eos.get_1D_var(f_VD_ptr, var) \n",
    "                    if two_D == True:\n",
    "                        _var = read_var_eos.get_2D_var(f_SD_ptr, f_VD_ptr, var)\n",
    "                        \n",
    "                    # assign np.nan where missing vallues\n",
    "                    _var[np.where(_var == -999.)] = np.nan\n",
    "                                \n",
    "                    f_VD_ptr.close()\n",
    "                    f_SD_ptr.end()\n",
    "\n",
    "                    # create dataset\n",
    "                    if one_D == True:\n",
    "                        _ds = fct.create_xr_1D_ds(Profile_time, _lat, _lon, _Data_quality, var, unit, _var)\n",
    "\n",
    "\n",
    "                        \n",
    "                    if two_D == True:\n",
    "                        # Read in ECMWF-Aux files for pressure averaging for 2D files\n",
    "                        f_SD_ptr = pySD.SD(ff_ec[i], pySD.SDC.READ)\n",
    "                        f_VD_ptr = pyHDF.HDF(ff_ec[i], pyHDF.HC.READ)\n",
    "\n",
    "                        # # Sometimes different data products don’t have the same dimensions, e.g. 2007 granule 3853\n",
    "                        # if lwc.shape != iwc.shape:\n",
    "                        #     dimension_failure += 1\n",
    "                        #     print(‘Skipping granule (dimension failure)...’)\n",
    "                        #     continue\n",
    "                                    \n",
    "                        # get 2D variable\n",
    "                        pressure = read_var_eos.get_2D_var(f_SD_ptr, f_VD_ptr, 'Pressure')\n",
    "                        temperature = read_var_eos.get_2D_var(f_SD_ptr, f_VD_ptr, 'Temperature')\n",
    "                                    \n",
    "                        # convert pressure into hPa\n",
    "                        pressure[np.where(pressure == -999.)] = np.nan\n",
    "                        pressure = pressure /100.\n",
    "                                    \n",
    "                        # assign np.nan where missing vallues\n",
    "                        temperature[np.where(temperature == -999.)] = np.nan\n",
    "                                            \n",
    "                        f_VD_ptr.close()\n",
    "                        f_SD_ptr.end()\n",
    "                        # create dataset\n",
    "                        _ds = fct.create_xr_2D_ds(Profile_time, _lat, _lon, _Data_quality, pressure, temperature, var, unit, _var)\n",
    "\n",
    "                        # assign pressure grid coordinate\n",
    "                        _ds = _ds.assign_coords(pressure_grid=pressure_grid)\n",
    "\n",
    "                        # define new variable to be on the pressure grid\n",
    "                        _ds[var+'_regrid'] = xr.DataArray(data=np.full(shape = (len(_ds.nray), len(_ds.pressure_grid)), fill_value = np.nan), dims=dict(nray=([]), pressure_grid=([])),)\n",
    "\n",
    "                        # put the 2D variable on equal pressure grid\n",
    "                        for t in range(len(_ds.nray)):\n",
    "                            for k in range(len(_ds.pressure_grid)):\n",
    "                                # First, find the index of the grid point nearest a specific pressure level\n",
    "                                abs_pressure = np.abs(_ds.pressure.isel(nray = t) - _ds.pressure_grid.isel(pressure_grid = k))\n",
    "                                c = abs_pressure\n",
    "\n",
    "                                try:\n",
    "                                    ([xloc, ]) = np.where(c == np.nanmin(c))\n",
    "                                    # Now I can use that index location to get the values at the x/y diminsion\n",
    "                                    _ds[var+'_regrid'][t, xloc] = _ds.snowfall_rate.isel(nray = t).sel(nbin = xloc)\n",
    "                                \n",
    "                                except:\n",
    "                                    print('c values', np.nanmin(c))\n",
    "                                    _ds[var+'_regrid'][t, xloc] = np.nan\n",
    "                                    \n",
    "                        _ds = _ds.drop_vars(var)                        \n",
    "\n",
    "                    ds = xr.concat([ds, _ds], dim = 'nray')\n",
    "\n",
    "            ds.to_netcdf(path = '{savepath}{filename}'.format(savepath = savepath, filename = filename))\n",
    "            print('file saved: {savepath}{filename}'.format(savepath = savepath, filename = filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b84f42cebd04cc021deb87758cb3e402c558a0fb4f3a5e5dab058aff4257489e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('globalsnow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
